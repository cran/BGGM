<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Donald R. Williams" />


<title>Comparing GGMs with the Posterior Predicive Distribution</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Comparing GGMs with the Posterior Predicive Distribution</h1>
<h4 class="author">Donald R. Williams</h4>


<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#test-statistic-loss-function">Test Statistic (Loss Function)</a></li>
</ul></li>
<li><a href="#posterior-predictive-method">Posterior Predictive Method</a></li>
<li><a href="#illustrative-example-1">Illustrative Example (1)</a><ul>
<li><a href="#personality-networks">Personality Networks</a><ul>
<li><a href="#summary">Summary</a></li>
<li><a href="#plot">Plot</a></li>
</ul></li>
</ul></li>
<li><a href="#illustrative-example-2">Illustrative Example (2)</a><ul>
<li><a href="#network-replicability">Network Replicability</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The <strong>BGGM</strong> package provides several options for comparing Gaussian graphical model. The approach presented here is based on the posterior predictive distribution. The idea is that generated data from the fitted model should look like the observed data (<span class="math inline">\(\textbf{Y}\)</span>). In the case of a well fitting model, the replicated data, herein referred to as <span class="math inline">\(\textbf{Y}^{rep}\)</span>, can be viewed as data that could have been observed (but were not) or as predictive data of future observations (Rubin, 1984). We adopt the latter perspective. This is summarized in Gelman (2006):</p>
<blockquote>
<p>“as the data that would appear if the experiment that produced <span class="math inline">\(\textbf{Y}\)</span> today were replicated tomorrow with the same model, <span class="math inline">\(\mathcal{M}\)</span>, [and] the same (unknown) value of <span class="math inline">\(\theta\)</span> that produced <span class="math inline">\(\textbf{Y}\)</span> (pp. 737).”</p>
</blockquote>
<p>Our approach extends “experiments” to the more general “data generating process.” In the context of comparing GGM’s, say, between two groups, the approach is to first estimate the GGM (i.e., the precision matrix denoted <span class="math inline">\(\boldsymbol{\Theta}\)</span> ) conditional on all of the groups being equal. Then the posterior predictive distribution can be sampled from <span class="math inline">\(\boldsymbol{\Theta}\)</span>. <span class="math inline">\(\textbf{Y}^{rep}\)</span> then represents the data that we expect to observe in the future, assuming that the fitted model of group equality was the underlying data generating process.</p>
<p>Assuming that each group <span class="math inline">\(g \in {1, ...,G}\)</span> is a realization from the same multivariate normal distribution, the null model is defined as</p>
<p><span class="math display">\[
\mathcal{M}_0 : \boldsymbol{\Theta}_1 = ... =  \boldsymbol{\Theta}_G
\]</span></p>
<p>The posterior for the common precision matrix <span class="math inline">\(\boldsymbol{\Theta}(= \boldsymbol{\Theta}_1 = . . . = \boldsymbol{\Theta}_G)\)</span>, given the observed data, can be written as <span class="math inline">\(p(\boldsymbol{\Theta}|\textbf{Y}^{obs}_1 , . . . , \textbf{Y}^{obs}_G, \mathcal{M}_0)\)</span>. Under <span class="math inline">\(\mathcal{M}_0\)</span>, a posterior draw (<span class="math inline">\(s\)</span>) for <span class="math inline">\(\boldsymbol{\Theta}^{(s)}\)</span> is in fact a posterior draw for the precision matrix in all groups, i.e., <span class="math inline">\(\boldsymbol{\Theta}^{(s)} = \boldsymbol{\Theta}^{(s)}_1,..., \boldsymbol{\Theta}^{(s)}_G\)</span>.</p>
<p>In review, it was pointed out by Sacha Epskamp that focusing on the precision matrix is not ideal, because it includes the diagonal elements which are not all that important for network <em>infernece</em>. Hence, to address this concern, we followed the approach in X and normalized <span class="math inline">\(\boldsymbol{\Theta}\)</span> as</p>
<p><span class="math display">\[
\boldsymbol\Theta = \textbf{D}\textbf{R}^{\Theta}\textbf{D}
\]</span> where <span class="math inline">\(\textbf{D}\)</span> is a diagonal matrix with <span class="math inline">\(\textbf{D}_{ii} = \sqrt{\boldsymbol{\Theta}}_{ii}\)</span> and <span class="math inline">\(\textbf{R}^{\Theta}\)</span> has <span class="math inline">\(r_{ij} = \Theta_{ij} / \sqrt{\Theta_{ii} \Theta_{jj}}\)</span> on the off-diagonals and 1 on the diagonal. This effectively separates out the diagonal elements of <span class="math inline">\(\boldsymbol{\Theta}\)</span>. Note <span class="math inline">\(\textbf{R}^{\Theta}\)</span> is <em>not</em> the partial correlation–that would require reversing the direction (<span class="math inline">\(\pm\)</span>) of <span class="math inline">\(r_{ij}\)</span>. However, we found that reversing the direction can result in ill-conditioned matrices. Hence <code>ggm_compare_ppc</code> currently makes use of the normalized precision matrix <span class="math inline">\(\textbf{R}^{\Theta}\)</span>.</p>
<div id="test-statistic-loss-function" class="section level2">
<h2>Test Statistic (Loss Function)</h2>
<p>For the test-statistic, that is used to compare groups, we use a version of Kullback-Leibler divergence (KLD), which is also known as entropy loss (Kuismin &amp; Sillanpää, 2017), is proportional (i.e., by 12) to Stein’s loss for covariance matrices (e.g., equation (72) in: James &amp; Stein, 1961), and is the log likelihood ratio between two distributions (Eguchi &amp; Copas, 2006). Note that KLD has several motivations, for example maximizing the likelihood is equivalent to minimizing KLD between two distributions (Grewal, 2011). Further, in Bayesian contexts, it has been used for selecting models (Goutis, 1998; Piironen &amp; Vehtari, 2017) and prior distributions (Bernardo, 2005), variational inference (Blei, Kucukelbir, &amp; McAuliffee, 2017), and is known to be minimized by the Bayes factor (when used for model selection) in so-called <span class="math inline">\(\mathcal{M}\)</span>-open settings (Bernardo &amp; Smith, 2001; Yao, Vehtari, Simpson, &amp; Gelman, 2017).</p>
<p>These uses have one common theme–i.e., assessing the entropy between distributions. However, KLD is not a true distance measure because it is asymmetric. As such, we use Jensen-Shannon divergence (JSD) which symmetrizes KLD (Nielsen, 2010). For, say, two groups, the test-statistic is then</p>
<p><span class="math display">\[
T(\textbf{Y}_{1}, \textbf{Y}_2) = \text{JSD}\Big(E\{\textbf{R}^{\Theta}_{g1} | \textbf{Y}_{g1}  \}, E\{\textbf{R}^{\Theta}_{g2} | \textbf{Y}_{g2}  \}\Big)
\]</span> which is the average KLD in both directions-i.e.,</p>
<p><span class="math display">\[
\text{JSD} = \frac{1}{2}\Big[\text{KLD}(E\{\textbf{R}^{\Theta}_{g1} | \textbf{Y}_{g1}\}, \{\textbf{R}^{\Theta}_{g2} | \textbf{Y}_{g2}\}) + \text{KLD}(E\{\textbf{R}^{\Theta}_{g2} | \textbf{Y}_{g2}\}, \textbf{R}^{\Theta}_{g1} | \textbf{Y}_{g1})\Big]
\]</span></p>
<p>For a multivariate normal distribution KLD is defined as</p>
<p><span class="math display">\[
\text{KLD}(\textbf{R}^{\Theta}_{g1} || \textbf{R}^{\Theta}_{g2}) = \frac{1}{2}\Big[\text{tr}(\textbf{R}^{\Theta^{-1}}_{g1}\textbf{R}^{\Theta^{-1}}_{g2}) - \text{log}(|\textbf{R}^{\Theta^{-1}}_{g1} \textbf{R}^{\Theta}_{g1}|) - p  \Big]
\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the number of variables. Note that inverting <span class="math inline">\(\textbf{R}^{\Theta}_{g1}\)</span> results in the covariance matrix and the expectation E[.] has been removed to simplify notation.</p>
</div>
</div>
<div id="posterior-predictive-method" class="section level1">
<h1>Posterior Predictive Method</h1>
<p>To summarize, our method follows these steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate <span class="math inline">\(p(\textbf{R}^{\Theta}|\textbf{Y}_1^{obs},\ldots,\textbf{Y}_G^{obs},\mathcal{M}_0)\)</span></li>
<li>For each posterior sample (<span class="math inline">\(s\)</span>)</li>
</ol>
<ul>
<li><span class="math inline">\(\textbf{R}^{\Theta^{(s)}}_g \rightarrow \textbf{Y}^{rep^{(s)}}_g\)</span>, for <span class="math inline">\(g \in \{1,..., G\}\)</span></li>
<li>Compute <span class="math inline">\(\textbf{R}^{\Theta^{rep^{(s)}}}_g\)</span> as <span class="math inline">\((n - 1)\textbf{S}^{-1}\)</span>, where  is <span class="math inline">\(\textbf{Y}_{g}^{rep^{(s)}\prime}\)</span> <span class="math inline">\(\textbf{Y}_{g}^{rep^{(s)}}\)</span>, for <span class="math inline">\(g \in \{1,..., G\}\)</span></li>
<li>For, say, two groups, compute the predictive entropy: <span class="math inline">\(\text{JSD}(E\{\textbf{R}^{\Theta^{rep^{(s)}}}_{g1} | \textbf{Y}^{rep^{(s)}}_{g1}\}, E\{\textbf{R}^{\Theta^{rep^{(s)}}}_{g2} | \textbf{Y}^{rep^{(s)}}_{g2}\} )\)</span></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Compute the observed entropy:</li>
</ol>
<ul>
<li><span class="math inline">\(\text{JSD}(E\{\textbf{R}^{\Theta^{obs}}_{g1} | \textbf{Y}_{g1}^{obs}\},E\{\textbf{R}^{\Theta^{obs}}_{g2} | \textbf{Y}_{g2}^{obs}\} )\)</span></li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Compute the posterior predictive <span class="math inline">\(p\)</span>-value.</li>
</ol>
<p>Note that <span class="math inline">\(g1\)</span> and <span class="math inline">\(g2\)</span> were used to keep the notation manageable. This procedure can apply to any number of groups. And the predictive <span class="math inline">\(p\)</span>-value is the proportion of the predictive distribution, assuming <span class="math inline">\(\mathcal{M}_0\)</span> is true (the groups are the same), that exceeds the observed JSD.</p>
</div>
<div id="illustrative-example-1" class="section level1">
<h1>Illustrative Example (1)</h1>
<div id="personality-networks" class="section level2">
<h2>Personality Networks</h2>
<p>To demonstrate this method, we will first compare personality networks between males and females. This allows for determing whether the null hypothesis of group (males vs. females) equality can be rejected. These data are located in the <strong>psych</strong> package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1">dat &lt;-<span class="st"> </span>BGGM<span class="op">::</span>bfi </a>
<a class="sourceLine" id="cb1-2" title="2"></a>
<a class="sourceLine" id="cb1-3" title="3">dat_males &lt;-<span class="st"> </span><span class="kw">subset</span>(dat, gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)[,<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>]</a>
<a class="sourceLine" id="cb1-4" title="4"></a>
<a class="sourceLine" id="cb1-5" title="5">dat_female &lt;-<span class="st"> </span><span class="kw">subset</span>(dat, gender <span class="op">==</span><span class="st"> </span><span class="dv">2</span>)[,<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>]</a>
<a class="sourceLine" id="cb1-6" title="6"></a>
<a class="sourceLine" id="cb1-7" title="7"><span class="co"># fit model</span></a>
<a class="sourceLine" id="cb1-8" title="8">fit1 &lt;-<span class="st"> </span><span class="kw">ggm_compare_ppc</span>(dat_males, </a>
<a class="sourceLine" id="cb1-9" title="9">                        dat_female, </a>
<a class="sourceLine" id="cb1-10" title="10">                        <span class="dt">iter =</span> <span class="dv">500</span>, </a>
<a class="sourceLine" id="cb1-11" title="11">                        <span class="dt">cores =</span> <span class="dv">4</span>)</a></code></pre></div>
<div id="summary" class="section level3">
<h3>Summary</h3>
<p>Once the model is finished, we can then use <code>summary</code>–i.e.,</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">summary</span>(fit1)</a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co">#&gt; BGGM: Bayesian Gaussian Graphical Models </span></a>
<a class="sourceLine" id="cb2-3" title="3"><span class="co">#&gt; --- </span></a>
<a class="sourceLine" id="cb2-4" title="4"><span class="co">#&gt; Type: GGM Comparison (Global Predictive Check) </span></a>
<a class="sourceLine" id="cb2-5" title="5"><span class="co">#&gt; Posterior Samples: 500 </span></a>
<a class="sourceLine" id="cb2-6" title="6"><span class="co">#&gt;   Group 1: 805 </span></a>
<a class="sourceLine" id="cb2-7" title="7"><span class="co">#&gt;   Group 2: 1631 </span></a>
<a class="sourceLine" id="cb2-8" title="8"><span class="co">#&gt; Variables (p): 25 </span></a>
<a class="sourceLine" id="cb2-9" title="9"><span class="co">#&gt; Edges: 300 </span></a>
<a class="sourceLine" id="cb2-10" title="10"><span class="co">#&gt; --- </span></a>
<a class="sourceLine" id="cb2-11" title="11"><span class="co">#&gt; Call: </span></a>
<a class="sourceLine" id="cb2-12" title="12"><span class="co">#&gt; ggm_compare_ppc(dat_males, dat_female, iter = 500, cores = 4)</span></a>
<a class="sourceLine" id="cb2-13" title="13"><span class="co">#&gt; --- </span></a>
<a class="sourceLine" id="cb2-14" title="14"><span class="co">#&gt; Estimates: </span></a>
<a class="sourceLine" id="cb2-15" title="15"><span class="co">#&gt;  </span></a>
<a class="sourceLine" id="cb2-16" title="16"><span class="co">#&gt;      contrast       KLD p_value</span></a>
<a class="sourceLine" id="cb2-17" title="17"><span class="co">#&gt;  Y_g1 vs Y_g2 0.4424236       0</span></a>
<a class="sourceLine" id="cb2-18" title="18"><span class="co">#&gt; --- </span></a>
<a class="sourceLine" id="cb2-19" title="19"><span class="co">#&gt; note: </span></a>
<a class="sourceLine" id="cb2-20" title="20"><span class="co">#&gt; p_value = p(T(Y_rep) &gt; T(y)|Y)</span></a>
<a class="sourceLine" id="cb2-21" title="21"><span class="co">#&gt; KLD = (symmetric) Kullback-Leibler divergence</span></a></code></pre></div>
<p>In this summary, the results are provided after <code>Estimate:</code>. The contrast is for which groups were compared. In this case, there were only two groups so there is one contrast. The third column provides the posterior predictive <span class="math inline">\(p\)</span>-value. In this case, because <span class="math inline">\(p\)</span>-value = 0, we can reject the null model <span class="math inline">\(\mathcal{M}_0\)</span> that assumes group equality. Hence, there is sufficient evidence to conclude that the personality networks for males and females are different from one another.</p>
</div>
<div id="plot" class="section level3">
<h3>Plot</h3>
<p>It is then possible to plot the predictive distribution and the observed value. This allows for visualizing the predictive approach–i.e.,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">plot</span>(fit1, <span class="dt">critical =</span> <span class="fl">0.05</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb3-2" title="2"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a>
<a class="sourceLine" id="cb3-4" title="4"><span class="co">#&gt; Picking joint bandwidth of 0.00614</span></a></code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p>This plot corresponds to the summary output, in that, as can be seen, the observed JSD (black point) far exceeds what we would expect if the groups were actually equal. The red area corresponds to the chosen <span class="math inline">\(\alpha\)</span> level. Hence, when the observed is within or beyond the critical region <span class="math inline">\(\mathcal{M}_0\)</span> (group equality), can be rejected.</p>
</div>
</div>
</div>
<div id="illustrative-example-2" class="section level1">
<h1>Illustrative Example (2)</h1>
<div id="network-replicability" class="section level2">
<h2>Network Replicability</h2>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
